{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/qDGA86xv6unXyRC0WpSX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PriyaShah-79/CloudCredits-Internship/blob/main/Sentiment%20Analysis%20on%20Movie%20Reviews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# 1. Download the dataset files\n",
        "path = kagglehub.dataset_download(\"lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# 2. List the files in the directory to find the CSV\n",
        "files = os.listdir(path)\n",
        "print(\"Files found:\", files)\n",
        "\n",
        "# 3. Load the specific CSV file\n",
        "# Most Kaggle datasets have the CSV inside the downloaded folder\n",
        "csv_file = [f for f in files if f.endswith('.csv')][0]\n",
        "df = pd.read_csv(os.path.join(path, csv_file))\n",
        "\n",
        "# 4. Preview the data\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lygvkwxQQt3D",
        "outputId": "a9a3f4d7-732b-4a50-897e-b8a6206dec09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'imdb-dataset-of-50k-movie-reviews' dataset.\n",
            "Path to dataset files: /kaggle/input/imdb-dataset-of-50k-movie-reviews\n",
            "Files found: ['IMDB Dataset.csv']\n",
            "                                              review sentiment\n",
            "0  One of the other reviewers has mentioned that ...  positive\n",
            "1  A wonderful little production. <br /><br />The...  positive\n",
            "2  I thought this was a wonderful way to spend ti...  positive\n",
            "3  Basically there's a family where a little boy ...  negative\n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# 1. Preprocessing Function (Cleaning HTML and special characters)\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub('<.*?>', '', text) # Remove HTML tags\n",
        "    text = re.sub('[^a-zA-Z]', ' ', text) # Keep only letters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip() # Remove extra spaces\n",
        "    return text\n",
        "\n",
        "# Apply cleaning to the dataframe we loaded previously\n",
        "df['review'] = df['review'].apply(clean_text)\n",
        "\n",
        "# 2. Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['review'], df['sentiment'], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 3. Create a Pipeline\n",
        "# This ensures that any new text passed to the model is vectorized exactly like the training data\n",
        "model_pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(stop_words='english', max_features=5000)),\n",
        "    ('nb', MultinomialNB())\n",
        "])\n",
        "\n",
        "# 4. Train the model\n",
        "model_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 5. Evaluate\n",
        "y_pred = model_pipeline.predict(X_test)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2%}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# 6. SAVE THE MODEL (Crucial for Deployment)\n",
        "joblib.dump(model_pipeline, 'movie_sentiment_model.pkl')\n",
        "print(\"Model saved as movie_sentiment_model.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKPhsCJeT5Pr",
        "outputId": "569b11a9-c9fd-461d-a5c7-2b58c8089066"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 50.00%\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.50      1.00      0.67         1\n",
            "    positive       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.50         2\n",
            "   macro avg       0.25      0.50      0.33         2\n",
            "weighted avg       0.25      0.50      0.33         2\n",
            "\n",
            "Model saved as movie_sentiment_model.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxI2n_rkUFRb",
        "outputId": "91dbfd46-7b8d-4d1d-8108-fc08d0b71c75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit\n",
        "!npm install -q localtunnel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2hmcf8ZUk6s",
        "outputId": "92e352d5-20f6-4596-db5e-6ab93abbd97c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K\n",
            "added 22 packages in 2s\n",
            "\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import joblib\n",
        "\n",
        "# Page config\n",
        "st.set_page_config(page_title=\"IMDb Sentiment AI\", page_icon=\"üé¨\")\n",
        "\n",
        "# Load model (Ensure you've saved movie_sentiment_model.pkl in your files)\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    return joblib.load('movie_sentiment_model.pkl')\n",
        "\n",
        "try:\n",
        "    model = load_model()\n",
        "    st.title(\"üé¨ Movie Review Sentiment AI\")\n",
        "    user_review = st.text_area(\"Enter a movie review:\")\n",
        "\n",
        "    if st.button(\"Predict Sentiment\"):\n",
        "        if user_review:\n",
        "            prediction = model.predict([user_review])[0]\n",
        "            if prediction == 'positive':\n",
        "                st.success(\"### Positive Sentiment! üåü\")\n",
        "            else:\n",
        "                st.error(\"### Negative Sentiment! üëé\")\n",
        "except:\n",
        "    st.error(\"Model file not found! Please run your training code first.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRODq1RUWUXL",
        "outputId": "5e79cb04-1ea5-468f-ab66-106d781fc604"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "print(\"COPY THIS IP ADDRESS:\", urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJrW1J1bWZoy",
        "outputId": "a2f4d284-31fd-4c52-cbe7-54920322eef6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COPY THIS IP ADDRESS: 34.139.149.180\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit\n",
        "!npm install -q localtunnel\n",
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgAIWWKWWefk",
        "outputId": "804c83ba-aaa6-4b85-f046-1a13b86f7cfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K\n",
            "up to date, audited 23 packages in 2s\n",
            "\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K\n",
            "2 \u001b[31m\u001b[1mhigh\u001b[22m\u001b[39m severity vulnerabilities\n",
            "\n",
            "To address all issues (including breaking changes), run:\n",
            "  npm audit fix --force\n",
            "\n",
            "Run `npm audit` for details.\n",
            "\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "your url is: https://rare-tables-kiss.loca.lt\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.139.149.180:8501\u001b[0m\n",
            "\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}